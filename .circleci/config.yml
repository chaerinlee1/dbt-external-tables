
version: 2.1

jobs:
  
  integration-redshift:
    docker:
      - image: circleci/python:3.6.3-stretch
    steps:
      - checkout
      - run:
          name: "Run Tests - Redshift"
          command: ./run_test.sh redshift
      - store_artifacts:
          path: ./logs
      
  integration-snowflake:
    docker:
      - image: circleci/python:3.6.3-stretch
    steps:
      - checkout
      - run:
          name: "Run Tests - Snowflake"
          command: ./run_test.sh snowflake
      - store_artifacts:
          path: ./logs
          
  integration-bigquery:
    environment:
      BIGQUERY_SERVICE_KEY_PATH: "/home/circleci/bigquery-service-key.json"
    docker:
      - image: circleci/python:3.6.3-stretch
    steps:
      - checkout
      - run:
          name: "Set up credentials"
          command: echo $BIGQUERY_SERVICE_ACCOUNT_JSON > ${HOME}/bigquery-service-key.json
      - run:
          name: "Run Tests - BigQuery"
          command: ./run_test.sh bigquery
      - store_artifacts:
          path: ./logs

  integration-databricks:
    environment:
      ODBC_DRIVER: Simba
    docker:
      # image based on `fishtownanalytics/test-container` w/ Simba ODBC Spark driver installed
      - image: 828731156495.dkr.ecr.us-east-1.amazonaws.com/dbt-spark-odbc-test-container:latest
        aws_auth:
          aws_access_key_id: $AWS_ACCESS_KEY_ID_STAGING
          aws_secret_access_key: $AWS_SECRET_ACCESS_KEY_STAGING
    steps:
      - checkout
      - run:
          name: "Run Tests - Databricks"
          command: ./run_test.sh databricks
      - store_artifacts:
          path: ./logs

  integration-synapse:
    docker:
      - image: dataders/pyodbc:1.2
    steps:
      - checkout
      - run:
          name: "Run Tests - synapse"
          command: ./run_test.sh synapse
      - store_artifacts:
          path: ./logs

  integration-azuresql:
    docker:
      - image: dataders/pyodbc:1.2
    steps:
      - checkout
      - run:
          name: "wait for Synapse tests to finish"
          command: sleep 60
      - run:
          name: "Run Tests - azuresql"
          command: ./run_test.sh azuresql
      - run:
          name: "Run Tests - azuresql (retry when server is off)"
          command: ./run_test.sh azuresql
          when: on_fail
      - store_artifacts:
          path: ./logs


workflows:
  version: 2
  test-all:
    jobs:
      - integration-redshift
      - integration-snowflake
      - integration-bigquery
      - integration-databricks
      - integration-synapse
      - integration-azuresql
